{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Prediction in the Greek Web\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we extract the texts from the folders..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import stemmer as st\n",
    "def process_word(word):\n",
    "    \"\"\"detone and stem word\n",
    "    \"\"\"\n",
    "    new_word = []\n",
    "    tones = { u'Ά' : u'A' , u'Έ': u'Ε', u'Ί': u'Ι', u'Ϊ': u'Ι',\n",
    "             u'Ύ': u'Υ', u'Ϋ': u'Υ', u'Ό' : u'Ο', u'Ή': u'Η', u'Ώ': u'Ω'}\n",
    "    for letter in word:\n",
    "        try:\n",
    "            new_word.append(tones[letter])\n",
    "        except KeyError:\n",
    "            new_word.append(letter)\n",
    "    detoned = ''.join(l for l in new_word)\n",
    "    return st.stem(detoned)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def process_text(data):\n",
    "    with open('dataset/greekstopwords.txt', 'r') as fp:\n",
    "        stopwords = []\n",
    "        for line in fp:\n",
    "            stopwords.append(line.strip().decode('utf-8').upper())\n",
    "    for domain in data.keys():\n",
    "        text = data[domain]\n",
    "        # remove punctuation\n",
    "        punctuation = set(string.punctuation)    \n",
    "        doc = ''.join([w for w in text if w not in punctuation])\n",
    "        # remove stopwords\n",
    "        doc = [w for w in doc.split() if w not in stopwords]\n",
    "        doc = [w for w in doc if not re.match(r\"$\\d+\\W+|\\b\\d+\\b|\\W+\\d+$\", w)]\n",
    "        doc = ' '.join(process_word(w) for w in doc)\n",
    "        data[domain] = doc\n",
    "    return data        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "if os.path.isfile('cache/processed_text.pickle'):\n",
    "    with open('cache/processed_text.pickle', 'rb') as pfile:\n",
    "        text_data = pickle.load(pfile)\n",
    "        print \"loaded from pickle\"\n",
    "else:\n",
    "    filenames = os.listdir('dataset/hosts')\n",
    "    raw_text = {}\n",
    "    for zipfilename in filenames:\n",
    "        with zipfile.ZipFile('dataset/hosts/'+zipfilename) as z:\n",
    "            text = \"\"\n",
    "            for filename in z.namelist():\n",
    "                if not os.path.isdir(filename):\n",
    "                    with z.open(filename) as f:\n",
    "                        for line in f:\n",
    "                            text += line.decode(\"utf-8\").upper()\n",
    "                            text += \" \"\n",
    "            raw_text[zipfilename[:-4]] = text\n",
    "    text_data = process_text(raw_text)\n",
    "    with open('cache/processed_text.pickle', 'wb') as pfile:\n",
    "        pickle.dump(text_data, pfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domain_number = {}\n",
    "for i, domain in enumerate(text_data.keys()):\n",
    "    domain_number[domain] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPNEWS247GREIDISEISPASOK\n",
      "ΠΕΜΠΤ\n",
      "ΟΚΤΩΒΡ\n",
      "ΠΟΛΙΤ\n",
      "ΚΟΙΝΩΝ\n",
      "ΟΙΚΟΝΟΜ\n",
      "ΚΟΣΜ\n",
      "ΓΝΩΜ\n",
      "ΠΑΡΑΣΚΗΝΙ\n",
      "ΠΡΩΤΟΣΕΛΙΔ\n",
      "ΡΟΗ\n",
      "ΠΕΡΙΣΣ\n",
      "ΥΓΕΙ\n",
      "LIFE\n",
      "GUIDE\n",
      "ΤΑΞΙΔ\n",
      "VIRAL\n",
      "ΨΥΧΑΓΩΓ\n",
      "ΦΑΓΗΤ\n",
      "CELEBRITIES\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "doc = [word for word in text_data['news247.gr'].split()[:20]]\n",
    "doc = [w for w in doc if not re.match(r\"$\\d+\\W+|\\b\\d+\\b|\\W+\\d+$\", w)]\n",
    "for w in doc:\n",
    "    print w\n",
    "    #print process_word(word.upper())\n",
    "    #print st.stem(word.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import networkx as nx\n",
    "import pprint\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2683\n",
      "2041\n"
     ]
    }
   ],
   "source": [
    "random.seed(1)\n",
    "edges = []\n",
    "with open('dataset/edgelist.txt', 'r')as fp:\n",
    "    for line in fp:\n",
    "        edges.append((line.split()[0], line.split()[1]))\n",
    "print len(edges)\n",
    "nodes = set([node for _tuple in edges for node in _tuple])\n",
    "print len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def compute_text_similarity(data):\n",
    "    vec = TfidfVectorizer(max_df=0.90, min_df=5, max_features=500,lowercase=False ,\n",
    "                          analyzer = 'word')\n",
    "    #vec = TfidfVectorizer(max_df=1, max_features=1000, lowercase=False)\n",
    "    x = vec.fit_transform(data)\n",
    "    for word in vec.get_feature_names():\n",
    "        print word,\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABOUT ALL AND ARE AT ATHENS AΔΕΙ AΛΛ AΝΘΡΩΠ AΡΘΡ AΤΟΜ BLOG BY COMMENT COMMENTS CONTACT COOKIES COPYRIGHT DE DESIGN EMAIL FACEBOOK FM FOR FROM GOOGLE GREECE GREEK HOME HOT IN IS IT JULY LED LIFESTYLE LIKE LIVE MAY MEDIA MORE NEW NEWS NEWSLETTER NO OCTOBER OF ON ONLINE OR OUT POST POSTED POWERED RADIO READ RESERVED RIGHTS RSS SEARCH SEPTEMBER SHARE SITE THE THIS TO TOP TWEET TWITTER US VIDEO VIEW WEB WITH YOU YOUR ΑΓ ΑΓΟΡ ΑΓΟΡA ΑΓΩΝ ΑΘΗΝ ΑΘΛΗΤ ΑΘΛΗΤΙΣΜ ΑΚΟΛΟΥΘ ΑΚΟΜ ΑΛΛ ΑΛΛA ΑΝAΠΤΥΞ ΑΝΑΖΗΤΗΣ ΑΝΑΚΟΙΝΩΣ ΑΝΘΡΩΠ ΑΠ ΑΠAΝΤΗΣ ΑΠΟ ΑΠΟΣΤΟΛ ΑΠΟΤΕΛ ΑΠΟΤΕΛΕΣΜ ΑΠΟΦAΣ ΑΠΟΦΑΣ ΑΠΟΨ ΑΠΡΙΛ ΑΠΡΙΛΙ ΑΡΘΡ ΑΡΙΘΜ ΑΡΧ ΑΡΧΕΙ ΑΣΦAΛΕΙ ΑΤΤ ΑΥΓ ΑΥΓΟΥΣΤ ΑΥΤ ΑΥΤA ΑΥΤΟΚΙΝΗΤ ΑΦ ΒAΣ ΒΑΘΜΟΛΟΓ ΒΙΒΛ ΒΙΒΛΙ ΒΙΝΤΕ ΒΟΛ ΒΡ ΒΡΙΣΚ ΓΕΝ ΓΕΡΜΑΝ ΓΕΩΡΓΙ ΓΙAΝΝ ΓΙΑΤ ΓΙΝ ΓΙΩΡΓ ΓΝΩΣΤ ΓΟΝ ΓΡAΦ ΓΡΑΦΕΙ ΓΡΗΓΟΡ ΓΥΝΑΙΚ ΔΕ ΔΕΔΟΜΕΝ ΔΕΚ ΔΕΚΕΜΒΡ ΔΗΛΩΣ ΔΗΜ ΔΗΜΗΤΡ ΔΗΜΙΟΥΡΓ ΔΗΜΟΣ ΔΗΜΟΣΙ ΔΗΜΟΣΙΕΥΘ ΔΗΜΟΣΙΕΥΣ ΔΗΜΟΤ ΔΗΜΟΦΙΛ ΔΙAΒΑΣ ΔΙAΡΚΕΙ ΔΙAΦΟΡ ΔΙΑΒAΣ ΔΙΑΒAΣΤ ΔΙΑΓΩΝΙΣΜ ΔΙΑΤΡΟΦ ΔΙΑΦΗΜΙΣ ΔΙΑΧΕΙΡΙΣ ΔΙΕΘΝ ΔΙΕΥΘΥΝΣ ΔΙΚΑΙ ΔΙΚΑΙΩΜ ΔΙΚΤΥ ΔΙΝ ΔΙΟΙΚΗΣ ΔΡAΣ ΔΡΑΣΤΗΡΙΟΤΗΤ ΔΡΟΜ ΔΥΝΑΜ ΔΥΝΑΤΟΤΗΤ ΔΥΟ ΔΥΣΚΟΛ ΔΩΡΕAΝ ΕΒΔΟΜAΔ ΕΓΓΡΑΦ ΕΓΙΝ ΕΔΩ ΕΘΝ ΕΙΔ ΕΙΔΗΣ ΕΙΚΟΝ ΕΙΜΑΣΤ ΕΙΝΑ ΕΙΠ ΕΙΧ ΕΚ ΕΚΔΗΛΩΣ ΕΚΔΟΣ ΕΚΕΙΝ ΕΚΘΕΣ ΕΚΛΟΓ ΕΚΠΑΙΔΕΥΣ ΕΚΠΑΙΔΕΥΤ ΕΚΤ ΕΛΕΓΧ ΕΛΕΥΘΕΡ ΕΛΛAΔ ΕΛΛΑΔ ΕΛΛΗΝ ΕΛΛΗΝΙΚ ΕΝ ΕΝΑ ΕΝΕΡΓΕΙ ΕΝΗΜΕΡΩΣ ΕΝΟΤΗΤ ΕΝΩ ΕΝΩΣ ΕΞΩΤΕΡ ΕΠΙ ΕΠΙΚΑΙΡΟΤΗΤ ΕΠΙΚΟΙΝΩΝ ΕΠΙΛΟΓ ΕΠΙΣ ΕΠΙΣΚΕΨ ΕΠΙΤΡΕΠ ΕΠΙΤΡΟΠ ΕΠΙΧΕΙΡΗΣ ΕΠΟΜΕΝ ΕΠΟΧ ΕΡΓ ΕΡΓΑΣ ΕΡΓΑΣΙ ΕΡΕΥΝ ΕΡΧ ΕΡΩΤΗΣ ΕΤ ΕΤΑΙΡ ΕΤΑΙΡΕΙ ΕΤΣ ΕΥΚΟΛ ΕΥΡ ΕΥΡΩΠ ΕΥΡΩΠΑΙΚ ΕΦΑΡΜΟΓ ΕΦΗΜΕΡΙΔ ΕΧ ΕΩΣ ΖΗΤ ΖΩ ΖΩΗ ΗΛΕΚΤΡΟΝ ΗΜΕΡ ΗΠΑ ΗΤ ΘΕΑΤΡ ΘΕΛ ΘΕΜ ΘΕΣ ΘΕΣΣΑΛΟΝ ΘΕΣΣΑΛΟΝΙΚ ΘΕΩΡ ΙΑΤΡ ΙΔ ΙΔΙ ΙΔΙΑΙΤΕΡ ΙΟΥΛ ΙΟΥΛΙ ΙΟΥΝ ΙΟΥΝΙ ΙΣΤΟΡ ΙΣΤΟΣΕΛΙΔ ΚAΘ ΚAΝ ΚAΠΟΙ ΚAΤ ΚΑΘ ΚΑΙΡ ΚΑΛ ΚΑΛAΘ ΚΑΝ ΚΑΤA ΚΑΤΑΣΚΕΥ ΚΑΤΗΓΟΡ ΚΑΤΗΓΟΡΙ ΚΑῚ ΚΕΝΤΡ ΚΙΝ ΚΛΙΚ ΚΟΙΝ ΚΟΙΝΟΤΗΤ ΚΟΙΝΩΝ ΚΟΣΜ ΚΡΗΤ ΚΡΙΣ ΚΥΒΕΡΝΗΣ ΚΥΠΡ ΚΥΡΙ ΚΥΡΙΑΚ ΚΩΔ ΚΩΝΣΤΑΝΤΙΝ ΛΕ ΛΕΙΤΟΥΡΓ ΛΙΓ ΛΙΣΤ ΛΟΓ ΛΟΓΑΡΙΑΣΜ ΛΥΣ ΜAΘ ΜAΙ ΜAΡΤΙ ΜΑΐ ΜΑΖ ΜΑΘΗΤ ΜΑΡ ΜΑΡΤ ΜΕΓAΛ ΜΕΓΑΛ ΜΕΛ ΜΕΡ ΜΕΣ ΜΕΤA ΜΕΤΑΞ ΜΕΤΡ ΜΕΧΡ ΜΗΝ ΜΗΝΥΜ ΜΙΑ ΜΙΚΡ ΜΜ ΜΟΙΡΑΣΤ ΜΟΝ ΜΟΝAΔ ΜΟΥΣ ΜΟΥΣΕΙ ΜΠΟΡ ΝΕ ΝΕΑ ΝΕΟ ΝΙΚΟΛΑ ΝΟΕΜΒΡ ΝΟΜ ΞΕΚΙΝ ΞΕΝΟΔΟΧΕΙ ΞΕΡ ΟΔΗΓ ΟΙΚΟΓΕΝΕΙ ΟΙΚΟΝΟΜ ΟΙΚΟΝΟΜΙΚ ΟΚΤ ΟΚΤΩΒΡ ΟΚΤΩΒΡΙ ΟΛ ΟΛΑ ΟΛΗ ΟΛΟΚΛΗΡ ΟΛΥΜΠΙΑΚ ΟΜ ΟΜAΔ ΟΜΙΛ ΟΝΟΜ ΟΠ ΟΠΟΙ ΟΡ ΟΡΓΑΝΙΣΜ ΟΣ ΟΣΟ ΟΤΙ ΟΥΤ ΟΧΙ ΠAΝ ΠAΝΤ ΠAΡ ΠΑΓΚΟΣΜ ΠΑΓΚΟΣΜΙ ΠΑΙΔ ΠΑΙΔΙA ΠΑΙΧΝΙΔ ΠΑΡΑΓΩΓ ΠΑΡΑΣΚΕΥ ΠΕΜΠΤ ΠΕΡ ΠΕΡΙΕΧΟΜΕΝ ΠΕΡΙΟΔ ΠΕΡΙΟΧ ΠΕΡΙΠΤΩΣ ΠΕΡΙΣΣ ΠΕΡΙΦΕΡΕΙ ΠΗΓ ΠΛΕ ΠΛΗΡΟΦΟΡΙ ΠΜ ΠΟΔΟΣΦΑΙΡ ΠΟΙΟΤΗΤ ΠΟΛ ΠΟΛΙΤ ΠΟΛΙΤΙΚ ΠΟΛΙΤΙΣΜ ΠΟΛΛ ΠΟΛΛA ΠΟΣ ΠΟΤ ΠΡΑΓΜΑΤΟΠΟΙ ΠΡΕΠ ΠΡΟΒΛΗΜ ΠΡΟΒΟΛ ΠΡΟΓΡAΜΜ ΠΡΟΓΡΑΜΜ ΠΡΟΕΔΡ ΠΡΟΗΓΟΥΜΕΝ ΠΡΟΙΟΝΤ ΠΡΟΣΚΛΗΣ ΠΡΟΣΦΑΤ ΠΡΟΣΦΕΡ ΠΡΟΣΦΟΡ ΠΡΟΣΩΠ ΠΡΟΤAΣ ΠΡΩΤ ΠΩΣ ΣAΒΒΑΤ ΣΕΛΙΔ ΣΕΠ ΣΕΠΤΕΜΒΡ ΣΕΠΤΕΜΒΡΙ ΣΗΜΕΙ ΣΗΜΕΡ ΣΠΙΤ ΣΤΑΘΜ ΣΤΗΛ ΣΤΙΓΜ ΣΤΟΙΧΕΙ ΣΤΟΧ ΣΥΓΚΕΚΡΙΜΕΝ ΣΥΛΛΟΓ ΣΥΜΒΟΥΛ ΣΥΜΒΟΥΛΙ ΣΥΜΜΕΤΟΧ ΣΥΜΦΩΝ ΣΥΝAΝΤΗΣ ΣΥΝΔΕΣ ΣΥΝΔΕΣΜ ΣΥΝΕΔΡΙ ΣΥΝΕΔΡΙΑΣ ΣΥΝΕΝΤΕΥΞ ΣΥΝΕΧΕΙ ΣΥΝΤΑΓ ΣΥΡΙΖ ΣΥΣΤΗΜ ΣΧΕΔ ΣΧΕΣ ΣΧΕΤΙΚA ΣΧΟΛ ΣΧΟΛΕΙ ΣΧΟΛΙ ΣΧΟΛΙΑΣΜ ΣΩΜ ΤΑΚΤ ΤΑΞΙΔ ΤΕΛ ΤΕΛΕΥΤΑΙ ΤΕΤAΡΤ ΤΕΥΧ ΤΕΧΝ ΤΕΧΝΟΛΟΓ ΤΗΛ ΤΗΛΕΦΩΝ ΤΙΜ ΤΙΤΛ ΤΜΗΜ ΤΟ ΤΟΠ ΤΟΣ ΤΟΤ ΤΟΥΡΙΣΜ ΤΟΥΡΚ ΤΟῦ ΤΡ ΤΡAΠΕΖ ΤΡΑΓΟΥΔ ΤΡΙΤ ΤΡΟΠ ΤΣΙΠΡ ΤΥΠ ΤΩΡ ΥΓΕΙ ΥΛ ΥΠAΡΧ ΥΠΗΡΕΣ ΥΠΗΡΕΣΙ ΥΠΟΥΡΓ ΥΨΗΛ ΦΕΣΤΙΒAΛ ΦΙΛ ΦΟΡ ΦΟΡA ΦΥΣΙΚ ΦΩΤ ΦΩΤΟΓΡΑΦ ΦΩΤΟΓΡΑΦΙ ΧAΡΤ ΧΡΕ ΧΡΗΣ ΧΡΗΣΙΜ ΧΡΗΣΙΜΟΠΟΙ ΧΡΗΣΤ ΧΡΟΝ ΧΡΥΣ ΧΩΡ ΧΩΡΙΣ ΩΡ ΩΡΑ (2041, 500)\n"
     ]
    }
   ],
   "source": [
    "X_text = compute_text_similarity(text_data.values())\n",
    "print X_text.shape\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine = cosine_similarity(X_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.478839219864\n"
     ]
    }
   ],
   "source": [
    "print cosine[domain_number['news247.gr'], domain_number['contra.gr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntopic extraction!\\nhttp://scikit-learn.org/stable/auto_examples/applications/topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-topics-extraction-with-nmf-lda-py'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "topic extraction!\n",
    "http://scikit-learn.org/stable/auto_examples/applications/topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-topics-extraction-with-nmf-lda-py\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_similarity(src, dst):\n",
    "    return cosine[domain_number[src], domain_number[dst]]  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_existent_edges = {}\n",
    "with open('dataset/not_existing_edges.txt', 'r')as fp:\n",
    "    for line in fp:\n",
    "        non_existent_edges[((line.split()[0], line.split()[1]))] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train, y_train= train_test_split(edges, test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2041\n",
      "2683\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pprint\n",
    "\n",
    "\"\"\"\n",
    "#G = nx.read_edgelist('dataset/edgelist.txt', delimiter='\\t', create_using=nx.DiGraph())\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from(X_train)\n",
    "G.add_nodes_from(nodes)\"\"\"\n",
    "G = nx.read_edgelist('dataset/edgelist.txt', delimiter='\\t', create_using=nx.DiGraph())\n",
    "print(len(G.nodes()))\n",
    "print(len(G.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4140197\n"
     ]
    }
   ],
   "source": [
    "non_edges = [edge for edge in list(nx.non_edges(G)) if not non_existent_edges.has_key(edge)]\n",
    "#4160957\n",
    "\n",
    "print len(non_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2683\n"
     ]
    }
   ],
   "source": [
    "sum_in_degree = sum(G.in_degree().values())\n",
    "print sum_in_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neighborhood(src, dst):\n",
    "    neigh = {}\n",
    "    neigh['out_src'] = G.out_degree(src)/G.degree(src)\n",
    "    neigh['in_dst'] = G.in_degree(dst)/G.degree(dst)\n",
    "    # maybe remove the next two features\n",
    "    #neigh['in_src'] = G.in_degree(src)/G.degree(src)\n",
    "    #neigh['out_dst'] = G.out_degree(dst)/G.degree(dst)    \n",
    "    src_neigh = list(nx.all_neighbors(G, src))\n",
    "    dst_neigh = list(nx.all_neighbors(G, dst))\n",
    "    #neigh['common_neighbors'] = len(set(src_neigh).intersection(dst_neigh))/(G.degree(src)+G.degree(dst))\n",
    "    out_dst = [a for _, a in G.out_edges(dst)]\n",
    "    in_dst = [a for a, _ in G.in_edges(dst)]\n",
    "    out_src = [a for _, a in G.out_edges(src)]    \n",
    "    in_src = [a for a, _ in G.in_edges(src)]\n",
    "    try:\n",
    "        neigh['n_common_in'] = len(set(in_src).intersection(in_dst))/(G.in_degree(src)+G.in_degree(dst))\n",
    "    except ZeroDivisionError:\n",
    "        neigh['n_common_in'] = 0\n",
    "    try:\n",
    "        neigh['n_common_out'] = len(set(out_src).intersection(out_dst))/(G.out_degree(src)+G.out_degree(dst))\n",
    "    except ZeroDivisionError:\n",
    "        neigh['n_common_out'] = 0\n",
    "    return neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pagerank = nx.pagerank(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "betweeness = nx.betweenness_centrality(G)\n",
    "closeness = nx.closeness_centrality(G)\n",
    "eigenvector = nx.eigenvector_centrality(G)\n",
    "degree = nx.degree_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def adamic_adar(src, dst):\n",
    "    score = 0\n",
    "    common = list(set(G.neighbors(src)).intersection(G.neighbors(dst)))\n",
    "    for node in common:\n",
    "        score += 1/np.log(len(G.neighbors(node)))\n",
    "    return sum(1 / math.log(G.degree(w))\n",
    "                   for w in common)     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0020540579927957"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adamic_adar('news247.gr', 'contra.gr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def src_features(node):\n",
    "    features = []\n",
    "    features.append(pagerank[node])\n",
    "    features.append(betweeness[node])\n",
    "    features.append(closeness[node])\n",
    "    features.append(eigenvector[node])\n",
    "    features.append(degree[node])\n",
    "    return features\n",
    "\n",
    "def dst_features(node):\n",
    "    features = []\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrix = nx.adjacency_matrix(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import louvain_igraph as louvain\n",
    "G_new = ig.Graph()\n",
    "G_new.add_vertices(G.nodes())\n",
    "G_new.add_edges(G.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt = louvain.Optimiser()\n",
    "partition = opt.find_partition(graph=G_new,partition_class=louvain.SignificanceVertexPartition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "partition = list(partition)\n",
    "partition_names = []\n",
    "for com in partition:\n",
    "    new_com = []\n",
    "    for node_id in com:\n",
    "        new_com.append(G_new.vs[node_id]['name'])\n",
    "    partition_names.append(new_com)\n",
    "# extract names\n",
    "partitions = { node : [] for node in G.nodes()}\n",
    "for com in partition_names:\n",
    "    for node in com:\n",
    "        partitions[node].extend(com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'politikanet.gr', u'katafylli.gr', u'skopelosonline.gr', u'inital.gr', u'arcadiasports.gr', u'bookone1.gr', u'aoristies.gr', u'oraiokastro24.gr', u'siriosfm.gr', u'sdeeth.gr', u'mypatra.gr', u'radioamfilochia.gr', u'ekriti.gr', u'paok-athens.gr', u'sarakis.gr', u'venceremos33.blogspot.gr', u'sportcyclades.gr', u'omospondiadaniolipton.gr', u'pireasnow.gr', u'hysteria.gr', u'radiomanos.gr', u'katanalotis.gr', u'nexusmanagementconsultants.gr', u'misitimi.gr', u'oxafies.com', u'erassitexnikopodosfairo.blogspot.gr', u'pkteam.gr', u'betforthewinners.gr', u'eplski.gr', u'oragiaspor-dramas.gr', u'epskastorias.gr', u'freddonews.gr', u'frontpages.gr']\n"
     ]
    }
   ],
   "source": [
    "print partitions[G_new.vs[0]['name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def partition_check(src, dst):\n",
    "    counter = 0\n",
    "    for neigh in G.neighbors(src):\n",
    "        if neigh in partitions[dst]:\n",
    "            counter+=1\n",
    "    \"\"\"if src in partitions[dst]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\"\"\"\n",
    "    return counter\n",
    "    \n",
    "partition_check('news247.gr', 'ladylike.gr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_extraction_old(edge):\n",
    "    src, dst = edge\n",
    "    f_vector = []\n",
    "    f_vector.append(text_similarity(src, dst)*2)\n",
    "    f_vector.append(pagerank[src])\n",
    "    #f_vector.append(pagerank[dst])\n",
    "    edge_hood = neighborhood(src, dst)\n",
    "    # add features: out degree of src, in degree of dst, # of common in with out\n",
    "    #f_vector.extend([len(edge_hood['out_src']), len(edge_hood['in_dst']), edge_hood['n_common_in'], edge_hood['n_common_out']])\n",
    "    f_vector.extend(edge_hood.values())    \n",
    "    return f_vector  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef feature_extraction(edge):\\n    src, dst = edge\\n    f_vector = []\\n    f_vector.append(text_similarity(src, dst))\\n    #f_vector.append(pagerank[src])\\n    f_vector.append(pagerank[dst])\\n    f_vector.append(betweeness[src])\\n    f_vector.append(betweeness[dst])\\n    f_vector.append(closeness[dst])\\n    f_vector.append(closeness[src])\\n    f_vector.append(G.in_degree(dst)/G.degree(dst))\\n    f_vector.append(len(set(G.neighbors(src)).intersection(G.neighbors(dst))))\\n    if G.has_edge(dst,src):\\n        f_vector.append(1)\\n    else:\\n        f_vector.append(0)\\n    f_vector.append(adamic_adar(src, dst))\\n    f_vector.append(partition_check(src, dst))\\n    return f_vector\\n    \\n    def feature_extraction(edge):\\n    src, dst = edge\\n    f_vector = []\\n    f_vector.append(text_similarity(src, dst))\\n    #f_vector.append(pagerank[src])\\n    f_vector.append(eigenvector[dst])\\n    f_vector.append(pagerank[dst])\\n    f_vector.append(betweeness[src])\\n    f_vector.append(betweeness[dst])\\n    f_vector.append(closeness[dst])\\n    f_vector.append(closeness[src])\\n    union = len(set(G.neighbors(src)).union(G.neighbors(dst)))\\n    intersection = len(set(G.neighbors(src)).intersection(G.neighbors(dst)))\\n    f_vector.append(intersection)\\n    if union:\\n        f_vector.append(intersection/union)\\n    else:\\n        f_vector.append(0)\\n    f_vector.append(adamic_adar(src, dst))\\n    f_vector.append(partition_check(src, dst))\\n    if G.has_edge(dst,src):\\n        f_vector.append(1)\\n    else:\\n        f_vector.append(0)\\n    return f_vector'"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_extraction(edge):\n",
    "    src, dst = edge\n",
    "    f_vector = []\n",
    "    f_vector.append(text_similarity(src, dst))\n",
    "    f_vector.append(pagerank[src])\n",
    "    f_vector.append(eigenvector[src])\n",
    "    f_vector.append(eigenvector[dst])\n",
    "    f_vector.append(pagerank[dst])\n",
    "    f_vector.append(betweeness[src])\n",
    "    f_vector.append(betweeness[dst])\n",
    "    f_vector.append(closeness[dst])\n",
    "    f_vector.append(closeness[src])\n",
    "    f_vector.append(adamic_adar(src, dst))\n",
    "    f_vector.append(partition_check(src, dst))\n",
    "    return f_vector\n",
    "\n",
    "\"\"\"\n",
    "def feature_extraction(edge):\n",
    "    src, dst = edge\n",
    "    f_vector = []\n",
    "    f_vector.append(text_similarity(src, dst))\n",
    "    #f_vector.append(pagerank[src])\n",
    "    f_vector.append(pagerank[dst])\n",
    "    f_vector.append(betweeness[src])\n",
    "    f_vector.append(betweeness[dst])\n",
    "    f_vector.append(closeness[dst])\n",
    "    f_vector.append(closeness[src])\n",
    "    f_vector.append(G.in_degree(dst)/G.degree(dst))\n",
    "    f_vector.append(len(set(G.neighbors(src)).intersection(G.neighbors(dst))))\n",
    "    if G.has_edge(dst,src):\n",
    "        f_vector.append(1)\n",
    "    else:\n",
    "        f_vector.append(0)\n",
    "    f_vector.append(adamic_adar(src, dst))\n",
    "    f_vector.append(partition_check(src, dst))\n",
    "    return f_vector\n",
    "    \n",
    "    def feature_extraction(edge):\n",
    "    src, dst = edge\n",
    "    f_vector = []\n",
    "    f_vector.append(text_similarity(src, dst))\n",
    "    #f_vector.append(pagerank[src])\n",
    "    f_vector.append(eigenvector[dst])\n",
    "    f_vector.append(pagerank[dst])\n",
    "    f_vector.append(betweeness[src])\n",
    "    f_vector.append(betweeness[dst])\n",
    "    f_vector.append(closeness[dst])\n",
    "    f_vector.append(closeness[src])\n",
    "    union = len(set(G.neighbors(src)).union(G.neighbors(dst)))\n",
    "    intersection = len(set(G.neighbors(src)).intersection(G.neighbors(dst)))\n",
    "    f_vector.append(intersection)\n",
    "    if union:\n",
    "        f_vector.append(intersection/union)\n",
    "    else:\n",
    "        f_vector.append(0)\n",
    "    f_vector.append(adamic_adar(src, dst))\n",
    "    f_vector.append(partition_check(src, dst))\n",
    "    if G.has_edge(dst,src):\n",
    "        f_vector.append(1)\n",
    "    else:\n",
    "        f_vector.append(0)\n",
    "    return f_vector\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47883921986362765, 0.004009557602747434, 0.2705070374673354, 0.310522072601534, 0.0016805343926659456, 0.00022283606919962717, 2.1252247833905517e-05, 0.005404411764705882, 0.006550802139037433, 3.0020540579927957, 9]\n"
     ]
    }
   ],
   "source": [
    "vector = feature_extraction(('news247.gr','contra.gr'))\n",
    "print vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for edge in edges:\n",
    "    X_train.append(feature_extraction(edge))\n",
    "    y_train.append(1)\n",
    "for edge in non_existent_edges:\n",
    "    X_train.append(feature_extraction(edge))\n",
    "    y_train.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_predict = []\n",
    "for edge in non_edges:\n",
    "    X_predict.append(feature_extraction(edge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_n = np.array(X_train)\n",
    "y_train_n = np.array(y_train)\n",
    "X_predict_n = np.array(X_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn import preprocessing\\nX_train_n = preprocessing.scale(X_train_n)\\nX_predict_n = preprocessing.scale(X_predict_n)'"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale features\n",
    "\"\"\"from sklearn import preprocessing\n",
    "X_train_n = preprocessing.scale(X_train_n)\n",
    "X_predict_n = preprocessing.scale(X_predict_n)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PCA didnt work\\nfrom sklearn.decomposition import PCA\\npca = PCA(n_components=10)\\nX_train_n = pca.fit_transform(X_train)\\nX_predict_n = pca.fit_transform(X_predict)'"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"PCA didnt work\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=10)\n",
    "X_train_n = pca.fit_transform(X_train)\n",
    "X_predict_n = pca.fit_transform(X_predict)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23443, 11)\n",
      "(23443,)\n",
      "(4140197, 11)\n"
     ]
    }
   ],
   "source": [
    "print X_train_n.shape\n",
    "print y_train_n.shape\n",
    "print X_predict_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.svm import SVC\\nfrom sklearn.linear_model import SGDClassifier\\nreg = LogisticRegression()\\nsgd = SGDClassifier(loss=\"log\", penalty=\"l2\")\\nsvm = SVC(probability=True)\\n#reg.fit(X_train_n, y_train_n)\\n# pred = reg.predict_proba(X_predict_n)\\nsvm.fit(X_train_n, y_train_n)\\npred_svm = svm.predict_proba(X_predict_n)\\n#sgd.fit(X_train_n, y_train_n)\\n#pred_sgd = sgd.predict_proba(X_predict_n)\\n'"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "reg = LogisticRegression()\n",
    "sgd = SGDClassifier(loss=\"log\", penalty=\"l2\")\n",
    "svm = SVC(probability=True)\n",
    "#reg.fit(X_train_n, y_train_n)\n",
    "# pred = reg.predict_proba(X_predict_n)\n",
    "svm.fit(X_train_n, y_train_n)\n",
    "pred_svm = svm.predict_proba(X_predict_n)\n",
    "#sgd.fit(X_train_n, y_train_n)\n",
    "#pred_sgd = sgd.predict_proba(X_predict_n)\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "xgb = xgboost.XGBClassifier()\n",
    "xgb.fit(X_train_n, y_train_n)\n",
    "pred_xgb = xgb.predict_proba(X_predict_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.99911010e-01   8.89989897e-05]\n"
     ]
    }
   ],
   "source": [
    "probs = []\n",
    "print pred_xgb[0]\n",
    "for t in pred_xgb:\n",
    "    probs.append(t[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = sorted(range(len(probs)), key=lambda k: probs[k])[::-1][:453]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99908197, 0.99901986, 0.99883097, 0.99878412, 0.99877673, 0.99875224, 0.99863005, 0.99853814, 0.99850428, 0.99844295, 0.99842936, 0.99841297, 0.99839753, 0.99837506, 0.99827886, 0.99827886, 0.99825913, 0.99824393, 0.9982298, 0.99820161, 0.99819034, 0.99816811, 0.99815458, 0.99815458, 0.99815458, 0.99815458, 0.99815458, 0.99815458, 0.99814904, 0.99814701, 0.99810898, 0.9980768, 0.9980768, 0.99807632, 0.99807394, 0.99804282, 0.99798143, 0.99795282, 0.99793303, 0.99792516, 0.99791902, 0.99791795, 0.99791032, 0.99790287, 0.99790287, 0.99789399, 0.99789399, 0.99786925, 0.99786925, 0.9978689, 0.99786359, 0.99786347, 0.99783891, 0.99782324, 0.99779797, 0.99776077, 0.99774987, 0.99774951, 0.99774051, 0.99773139, 0.99773139, 0.99773139, 0.99773139, 0.9977144, 0.99771035, 0.99766123, 0.99765849, 0.99765414, 0.99759895, 0.99759442, 0.99759442, 0.99757665, 0.99756491, 0.99756491, 0.99756491, 0.99756491, 0.99754333, 0.99753821, 0.99753344, 0.99753112, 0.99753016, 0.99752027, 0.99751163, 0.9974885, 0.9974885, 0.99744874, 0.99744475, 0.99744475, 0.99744475, 0.99744475, 0.99744475, 0.99744475, 0.99744475, 0.99744475, 0.99744058, 0.99744058, 0.99744058, 0.99744058, 0.99744058, 0.99744058, 0.99744058, 0.99744058, 0.99744058, 0.99744058, 0.99744058, 0.99744058, 0.99744058, 0.99743408, 0.99743062, 0.9974094, 0.99737811, 0.99737811, 0.99737799, 0.99736148, 0.99736148, 0.99735451, 0.99735212, 0.99734986, 0.99734914, 0.99734443, 0.99733186, 0.99733019, 0.99733019, 0.99733019, 0.99733019, 0.99733019, 0.99733019, 0.99733019, 0.99733019, 0.99733019, 0.99733019, 0.99731255, 0.99731255, 0.99731255, 0.99729949, 0.99729949, 0.99729949, 0.99729592, 0.99729592, 0.99729592, 0.99728215, 0.99727875, 0.99727124, 0.99726969, 0.99726248, 0.99726248, 0.99724269, 0.99724162, 0.9972173, 0.9972173, 0.99720711, 0.99720496, 0.99720407, 0.99718034, 0.99718034, 0.99718034, 0.99717051, 0.99713659, 0.99713492, 0.99711847, 0.99709177, 0.99709177, 0.99707967, 0.99707127, 0.99706453, 0.99706453, 0.99705684, 0.99705005, 0.99703205, 0.99703109, 0.99701154, 0.99701118, 0.99695826, 0.99695826, 0.99695826, 0.99695826, 0.99695551, 0.99693942, 0.99693203, 0.99691808, 0.99691063, 0.99690694, 0.99690694, 0.99689603, 0.99689603, 0.99689603, 0.99689603, 0.99689603, 0.99689603, 0.99689603, 0.99689353, 0.99689204, 0.99688941, 0.996876, 0.99687397, 0.99687397, 0.99687397, 0.99687397, 0.99687397, 0.99687397, 0.99687117, 0.99686509, 0.99685788, 0.99685788, 0.99684948, 0.99684948, 0.99684948, 0.99682117, 0.99681431, 0.99681383, 0.99679703, 0.99679476, 0.99678886, 0.99678171, 0.99673742, 0.99673742, 0.99673742, 0.99673742, 0.99673718, 0.99672949, 0.99672949, 0.99672949, 0.99672949, 0.99672782, 0.99671644, 0.99669856, 0.99669856, 0.99669856, 0.99669856, 0.99669856, 0.99669832, 0.99668664, 0.99668664, 0.99667931, 0.99665821, 0.99665254, 0.99662137, 0.99662054, 0.99660468, 0.99660468, 0.99660373, 0.99658966, 0.99658966, 0.99658149, 0.99658149, 0.99658114, 0.99656314, 0.99656314, 0.99656314, 0.99656314, 0.99656206, 0.99655968, 0.99655759, 0.99655747, 0.99654621, 0.99654621, 0.99653208, 0.99653208, 0.99653208, 0.99651802, 0.9965089, 0.99650747, 0.99650109, 0.99650061, 0.99650061, 0.99647659, 0.99646878, 0.99645704, 0.99645621, 0.99645621, 0.99645621, 0.99645621, 0.99645507, 0.99644321, 0.99644321, 0.9964413, 0.99643874, 0.9964329, 0.99643147, 0.99642676, 0.99642122, 0.99642074, 0.99641657, 0.99641019, 0.99640346, 0.99640346, 0.99640346, 0.99639976, 0.99639976, 0.99639755, 0.99637872, 0.99637872, 0.99636215, 0.99636215, 0.99636215, 0.99636215, 0.99636215, 0.99636215, 0.99636215, 0.99636215, 0.99636084, 0.9963432, 0.99634236, 0.99633032, 0.9963277, 0.99632579, 0.99632132, 0.99632132, 0.99632132, 0.9963153, 0.99630821, 0.99630058, 0.99630058, 0.99629349, 0.99629116, 0.99628806, 0.99628806, 0.99628806, 0.99628806, 0.99628806, 0.99628806, 0.99628806, 0.99628806, 0.99628156, 0.99627787, 0.9962728, 0.9962669, 0.9962669, 0.99625129, 0.99625129, 0.996234, 0.996234, 0.99623376, 0.99621361, 0.99621361, 0.99621361, 0.99621361, 0.99621361, 0.9962126, 0.99621058, 0.99620914, 0.99620312, 0.99619663, 0.99619663, 0.99618137, 0.99615699, 0.99614149, 0.99612409, 0.99610966, 0.99609214, 0.99607545, 0.99607545, 0.99606162, 0.99606162, 0.99606091, 0.99605823, 0.99604923, 0.99604356, 0.99604356, 0.99604356, 0.99603194, 0.99602473, 0.99602473, 0.99600703, 0.99600559, 0.99600178, 0.99598938, 0.99598384, 0.99598384, 0.99597651, 0.99597025, 0.99596065, 0.99595946, 0.99595946, 0.99595886, 0.99595225, 0.99593073, 0.99591929, 0.99591929, 0.99591929, 0.99590033, 0.99590033, 0.99590033, 0.99589854, 0.9958759, 0.99587387, 0.99587387, 0.99586391, 0.99583352, 0.99582577, 0.99581486, 0.9958086, 0.9958086, 0.99580538, 0.9957847, 0.99577147, 0.99576533, 0.99576533, 0.99576181, 0.99574655, 0.99574655, 0.99574655, 0.99572647, 0.99572647, 0.99572241, 0.99571532, 0.99571252, 0.9957099, 0.9957099, 0.99570686, 0.99570125, 0.99570125, 0.99570125, 0.99569941, 0.99569941, 0.99569607, 0.99568981, 0.99568045, 0.9956792, 0.9956792, 0.9956792, 0.99567705, 0.99567258, 0.99565458, 0.99565458, 0.99565458, 0.99565458, 0.99565458, 0.99564677, 0.99564373, 0.99563879, 0.99563134, 0.99562705, 0.99562645, 0.99560392, 0.99560392, 0.99560249, 0.99560249, 0.99560249, 0.99557543, 0.99557543, 0.99555224, 0.99554944, 0.99554342, 0.99553251, 0.99553192, 0.99552983, 0.99552709, 0.99550074, 0.99549872, 0.99548435, 0.99548304, 0.99548304]\n"
     ]
    }
   ],
   "source": [
    "print [probs[indices[i]] for i in range(len(indices))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_edges = []\n",
    "for i in range(len(indices)):\n",
    "    predicted_edges.append(non_edges[indices[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'kidsfun.gr', u'proskliseis-kartes.gr'), (u'botanologia.blogspot.gr', u'left.gr'), (u'abtax.gr', u'doe.gr'), (u'efimerides.eu', u'instyle.gr'), (u'efimerides.eu', u'newmoney.gr')]\n"
     ]
    }
   ],
   "source": [
    "print predicted_edges[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('predicted_edges_xgb.txt', 'w') as fp:\n",
    "    for site_1, site_2 in predicted_edges:\n",
    "        fp.write(site_1+'\\t'+site_2+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
