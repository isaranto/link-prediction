{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Prediction in the Greek Web\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we extract the texts from the folders..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import stemmer as st\n",
    "def process_word(word):\n",
    "    \"\"\"detone and stem word\n",
    "    \"\"\"\n",
    "    new_word = []\n",
    "    tones = { u'Ά' : u'A' , u'Έ': u'Ε', u'Ί': u'Ι', u'Ϊ': u'Ι',\n",
    "             u'Ύ': u'Υ', u'Ϋ': u'Υ', u'Ό' : u'Ο', u'Ή': u'Η', u'Ώ': u'Ω'}\n",
    "    for letter in word:\n",
    "        try:\n",
    "            new_word.append(tones[letter])\n",
    "        except KeyError:\n",
    "            new_word.append(letter)\n",
    "    detoned = ''.join(l for l in new_word)\n",
    "    return st.stem(detoned)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def process_text(data):\n",
    "    with open('dataset/greekstopwords.txt', 'r') as fp:\n",
    "        stopwords = []\n",
    "        for line in fp:\n",
    "            stopwords.append(line.strip().decode('utf-8').upper())\n",
    "    for domain in data.keys():\n",
    "        text = data[domain]\n",
    "        # remove punctuation\n",
    "        punctuation = set(string.punctuation)    \n",
    "        doc = ''.join([w for w in text if w not in punctuation])\n",
    "        # remove stopwords\n",
    "        doc = [w for w in doc.split() if w not in stopwords]\n",
    "        doc = ' '.join(process_word(w) for w in doc)\n",
    "        data[domain] = doc\n",
    "    return data        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from pickle\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "if os.path.isfile('cache/processed_text.pickle'):\n",
    "    with open('cache/processed_text.pickle', 'rb') as pfile:\n",
    "        text_data = pickle.load(pfile)\n",
    "        print \"loaded from pickle\"\n",
    "else:\n",
    "    filenames = os.listdir('dataset/hosts')\n",
    "    raw_text = {}\n",
    "    for zipfilename in filenames:\n",
    "        with zipfile.ZipFile('dataset/hosts/'+zipfilename) as z:\n",
    "            text = \"\"\n",
    "            for filename in z.namelist():\n",
    "                if not os.path.isdir(filename):\n",
    "                    with z.open(filename) as f:\n",
    "                        for line in f:\n",
    "                            text += line.decode(\"utf-8\").upper()\n",
    "                            text += \" \"\n",
    "            raw_text[zipfilename[:-4]] = text\n",
    "    text_data = process_text(raw_text)\n",
    "    with open('cache/processed_text.pickle', 'wb') as pfile:\n",
    "        pickle.dump(text_data, pfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domain_number = {}\n",
    "for i, domain in enumerate(text_data.keys()):\n",
    "    domain_number[domain] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTPNEWS247GREIDISEISPASOK\n",
      "ΠΕΜΠΤ\n",
      "13\n",
      "ΟΚΤΩΒΡ\n",
      "2016\n",
      "ΠΟΛΙΤ\n",
      "ΚΟΙΝΩΝ\n",
      "ΟΙΚΟΝΟΜ\n",
      "ΚΟΣΜ\n",
      "ΓΝΩΜ\n",
      "ΠΑΡΑΣΚΗΝΙ\n",
      "ΠΡΩΤΟΣΕΛΙΔ\n",
      "ΡΟΗ\n",
      "ΠΕΡΙΣΣ\n",
      "ΥΓΕΙ\n",
      "LIFE\n",
      "GUIDE\n",
      "ΤΑΞΙΔ\n",
      "VIRAL\n",
      "ΨΥΧΑΓΩΓ\n"
     ]
    }
   ],
   "source": [
    "for word in text_data['news247.gr'].split()[:20]:\n",
    "    print word\n",
    "    #print process_word(word.upper())\n",
    "    #print st.stem(word.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import networkx as nx\n",
    "import pprint\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2683\n",
      "2041\n"
     ]
    }
   ],
   "source": [
    "random.seed(1)\n",
    "edges = []\n",
    "with open('dataset/edgelist.txt', 'r')as fp:\n",
    "    for line in fp:\n",
    "        edges.append((line.split()[0], line.split()[1]))\n",
    "print len(edges)\n",
    "nodes = set([node for _tuple in edges for node in _tuple])\n",
    "print len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def compute_text_similarity(data):\n",
    "    vec = TfidfVectorizer(max_df=0.98, min_df=2, max_features=1000)\n",
    "    x = vec.fit_transform(data)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2041, 55)\n"
     ]
    }
   ],
   "source": [
    "X_text = compute_text_similarity(text_data)\n",
    "print X_text.shape\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine = cosine_similarity(X_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13700047218\n"
     ]
    }
   ],
   "source": [
    "print cosine[domain_number['news247.gr'], domain_number['contra.gr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "n_topics = 10\n",
    "n_top_words = 20\n",
    "nmf = NMF(n_components=n_topics, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_similarity(src, dst):\n",
    "    return cosine[domain_number[src], domain_number[dst]]  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_existent_edges = {}\n",
    "with open('dataset/not_existing_edges.txt', 'r')as fp:\n",
    "    for line in fp:\n",
    "        non_existent_edges[((line.split()[0], line.split()[1]))] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train= train_test_split(edges, test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2041\n",
      "2683\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pprint\n",
    "\n",
    "\"\"\"\n",
    "#G = nx.read_edgelist('dataset/edgelist.txt', delimiter='\\t', create_using=nx.DiGraph())\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from(X_train)\n",
    "G.add_nodes_from(nodes)\"\"\"\n",
    "G = nx.read_edgelist('dataset/edgelist.txt', delimiter='\\t', create_using=nx.DiGraph())\n",
    "print(len(G.nodes()))\n",
    "print(len(G.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4140197\n"
     ]
    }
   ],
   "source": [
    "non_edges = [edge for edge in list(nx.non_edges(G)) if not non_existent_edges.has_key(edge)]\n",
    "#4160957\n",
    "\n",
    "print len(non_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2683\n"
     ]
    }
   ],
   "source": [
    "sum_in_degree = sum(G.in_degree().values())\n",
    "print sum_in_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neighborhood(src, dst):\n",
    "    neigh = {}\n",
    "    neigh['out_src'] = G.out_degree(src)/G.degree(src)\n",
    "    neigh['in_dst'] = G.in_degree(dst)/G.degree(dst)\n",
    "    # maybe remove the next two features\n",
    "    #neigh['in_src'] = G.in_degree(src)/G.degree(src)\n",
    "    #neigh['out_dst'] = G.out_degree(dst)/G.degree(dst)    \n",
    "    src_neigh = list(nx.all_neighbors(G, src))\n",
    "    dst_neigh = list(nx.all_neighbors(G, dst))\n",
    "    #neigh['common_neighbors'] = len(set(src_neigh).intersection(dst_neigh))/(G.degree(src)+G.degree(dst))\n",
    "    out_dst = [a for _, a in G.out_edges(dst)]\n",
    "    in_dst = [a for a, _ in G.in_edges(dst)]\n",
    "    out_src = [a for _, a in G.out_edges(src)]    \n",
    "    in_src = [a for a, _ in G.in_edges(src)]\n",
    "    try:\n",
    "        neigh['n_common_in'] = len(set(in_src).intersection(in_dst))/(G.in_degree(src)+G.in_degree(dst))\n",
    "    except ZeroDivisionError:\n",
    "        neigh['n_common_in'] = 0\n",
    "    try:\n",
    "        neigh['n_common_out'] = len(set(out_src).intersection(out_dst))/(G.out_degree(src)+G.out_degree(dst))\n",
    "    except ZeroDivisionError:\n",
    "        neigh['n_common_out'] = 0\n",
    "    return neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pagerank = nx.pagerank(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "betweeness = nx.betweenness_centrality(G)\n",
    "closeness = nx.closeness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#jaccard = nx.jaccard_coefficient(G,'news247.gr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_extraction_old(edge):\n",
    "    src, dst = edge\n",
    "    f_vector = []\n",
    "    f_vector.append(text_similarity(src, dst)*2)\n",
    "    f_vector.append(pagerank[src])\n",
    "    #f_vector.append(pagerank[dst])\n",
    "    edge_hood = neighborhood(src, dst)\n",
    "    # add features: out degree of src, in degree of dst, # of common in with out\n",
    "    #f_vector.extend([len(edge_hood['out_src']), len(edge_hood['in_dst']), edge_hood['n_common_in'], edge_hood['n_common_out']])\n",
    "    f_vector.extend(edge_hood.values())    \n",
    "    return f_vector  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef feature_extraction(edge):\\n    src, dst = edge\\n    f_vector = []\\n    f_vector.append(text_similarity(src, dst))\\n    f_vector.append(pagerank[src])\\n    f_vector.append(pagerank[dst])\\n    f_vector.append(betweeness[src])\\n    f_vector.append(betweeness[dst])\\n    f_vector.append(closeness[src])\\n    f_vector.append(closeness[dst])\\n    f_vector.append(G.out_degree(src)/G.degree(src))\\n    f_vector.append(G.in_degree(dst)/G.degree(dst))\\n    try:\\n        f_vector.append(len(set(G.neighbors(src)).intersection(G.neighbors(dst)))/len(set(G.neighbors(src)).union(G.neighbors(dst))))\\n    except ZeroDivisionError:\\n        f_vector.append(0)\\n    return f_vector'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_extraction(edge):\n",
    "    src, dst = edge\n",
    "    f_vector = []\n",
    "    f_vector.append(text_similarity(src, dst)*2)\n",
    "    f_vector.append(pagerank[src])\n",
    "    f_vector.append(pagerank[dst])\n",
    "    f_vector.append(betweeness[src])\n",
    "    f_vector.append(betweeness[dst])\n",
    "    f_vector.append(G.in_degree(dst)/G.degree(dst))\n",
    "    f_vector.append(len(set(G.neighbors(src)).intersection(G.neighbors(dst))))\n",
    "    if G.has_edge(dst,src):\n",
    "        f_vector.append(1)\n",
    "    else:\n",
    "        f_vector.append(0)\n",
    "    return f_vector\n",
    "\n",
    "\"\"\"\n",
    "def feature_extraction(edge):\n",
    "    src, dst = edge\n",
    "    f_vector = []\n",
    "    f_vector.append(text_similarity(src, dst))\n",
    "    f_vector.append(pagerank[src])\n",
    "    f_vector.append(pagerank[dst])\n",
    "    f_vector.append(betweeness[src])\n",
    "    f_vector.append(betweeness[dst])\n",
    "    f_vector.append(closeness[src])\n",
    "    f_vector.append(closeness[dst])\n",
    "    f_vector.append(G.out_degree(src)/G.degree(src))\n",
    "    f_vector.append(G.in_degree(dst)/G.degree(dst))\n",
    "    try:\n",
    "        f_vector.append(len(set(G.neighbors(src)).intersection(G.neighbors(dst)))/len(set(G.neighbors(src)).union(G.neighbors(dst))))\n",
    "    except ZeroDivisionError:\n",
    "        f_vector.append(0)\n",
    "    return f_vector\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print len(set(G.neighbors('news247.gr')).intersection(G.neighbors('contra.gr')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2740009443607388, 0.004009557602747434, 0.0016805343926659456, 0.00022283606919962717, 2.1252247833905517e-05, 0.5, 8, 0]\n"
     ]
    }
   ],
   "source": [
    "vector = feature_extraction(('news247.gr','contra.gr'))\n",
    "print vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for edge in edges:\n",
    "    X_train.append(feature_extraction(edge))\n",
    "    y_train.append(1)\n",
    "for edge in non_existent_edges:\n",
    "    X_train.append(feature_extraction(edge))\n",
    "    y_train.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_predict = []\n",
    "for edge in non_edges:\n",
    "    X_predict.append(feature_extraction(edge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_n = np.array(X_train)\n",
    "y_train_n = np.array(y_train)\n",
    "X_predict_n = np.array(X_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23443, 8)\n",
      "(23443,)\n",
      "(4140197, 8)\n"
     ]
    }
   ],
   "source": [
    "print X_train_n.shape\n",
    "print y_train_n.shape\n",
    "print X_predict_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "reg = LogisticRegression()\n",
    "sgd = SGDClassifier(loss=\"log\", penalty=\"l2\")\n",
    "svm = SVC(probability=True)\n",
    "#reg.fit(X_train_n, y_train_n)\n",
    "#sgd.fit(X_train_n, y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "xgb = xgboost.XGBClassifier()\n",
    "xgb.fit(X_train_n, y_train_n)\n",
    "pred_xgb = xgb.predict_proba(X_predict_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#svm.fit(X_train_n, y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pred = reg.predict_proba(X_predict_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred_sgd = sgd.predict_proba(X_predict_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pred_svm = svm.predict_proba(X_predict_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.75522542  0.24477461]\n"
     ]
    }
   ],
   "source": [
    "probs = []\n",
    "print pred_xgb[0]\n",
    "for t in pred_xgb:\n",
    "    probs.append(t[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = sorted(range(len(probs)), key=lambda k: probs[k])[::-1][:453]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99969029, 0.99959809, 0.99950826, 0.99949062, 0.99945682, 0.999376, 0.99936479, 0.99930727, 0.99929535, 0.99929535, 0.99908078, 0.99898082, 0.9989453, 0.99885046, 0.99870515, 0.99869305, 0.99856025, 0.99840122, 0.99806637, 0.99794275, 0.99793541, 0.99770987, 0.99770987, 0.99770987, 0.99740368, 0.99737823, 0.99731219, 0.99681658, 0.99600369, 0.99597186, 0.99580634, 0.9950965, 0.99473119, 0.99453211, 0.99450797, 0.9943198, 0.9938764, 0.99385214, 0.99352843, 0.99293453, 0.99286276, 0.99188691, 0.99080396, 0.99012429, 0.9897092, 0.98962456, 0.98910147, 0.98904991, 0.98884773, 0.98855674, 0.98847836, 0.98820132, 0.98766464, 0.98685604, 0.98669541, 0.98665988, 0.98641169, 0.98606747, 0.98599237, 0.98537999, 0.98463494, 0.98459321, 0.98417526, 0.9840135, 0.98377478, 0.98371947, 0.98364568, 0.9833551, 0.98264104, 0.98165786, 0.9811033, 0.98089361, 0.9808895, 0.98072368, 0.98047674, 0.98018152, 0.98004663, 0.97991496, 0.97991496, 0.9797799, 0.97960359, 0.97960359, 0.97940367, 0.97930497, 0.97917503, 0.97916698, 0.97899866, 0.97885346, 0.9785648, 0.97800434, 0.97800434, 0.97747254, 0.97737098, 0.97723925, 0.97718143, 0.97631675, 0.97619641, 0.97615814, 0.97581476, 0.97581476, 0.97581476, 0.97581476, 0.97540343, 0.97540343, 0.97539586, 0.97537076, 0.97536713, 0.97504377, 0.97504377, 0.97443342, 0.97443205, 0.97398472, 0.97332871, 0.97319973, 0.97319973, 0.97291881, 0.97288752, 0.97283578, 0.97283578, 0.97283578, 0.97273809, 0.97265446, 0.97263235, 0.9725309, 0.9724471, 0.9724471, 0.97205812, 0.97205812, 0.97205812, 0.97131586, 0.97096664, 0.97093505, 0.97077268, 0.97074991, 0.97074801, 0.97014016, 0.97006994, 0.97001517, 0.97000164, 0.96984023, 0.96973139, 0.96955931, 0.96955931, 0.96951634, 0.96942317, 0.96927524, 0.96895456, 0.96880406, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96850127, 0.96820706, 0.96820706, 0.96818984, 0.96818984, 0.96773976, 0.96773976, 0.96738464, 0.96707481, 0.96677786, 0.96639228, 0.96639228, 0.96639228, 0.96639228, 0.966075, 0.966075, 0.966075, 0.96592563, 0.96587121, 0.96585023, 0.96580952, 0.96563864, 0.96563864, 0.96560919, 0.96543646, 0.96543646, 0.96495718, 0.96488792, 0.9648242, 0.9648242, 0.96454495, 0.96451235, 0.96405554, 0.96381783, 0.96380603, 0.9635461, 0.96317083, 0.96315557, 0.96314937, 0.96295673, 0.96273041, 0.96241152, 0.96241152, 0.96241152, 0.96241152, 0.96241152, 0.96241152, 0.96241152, 0.96209991, 0.96209991, 0.96203685, 0.96202081, 0.96197766, 0.96184874, 0.96184641, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96144331, 0.96035808, 0.96012187, 0.9597258, 0.95966363, 0.95957869, 0.95957869, 0.95931792, 0.95931792, 0.95931792, 0.95926768, 0.95905024, 0.95890695, 0.95844054, 0.95844054, 0.9569208, 0.9569208, 0.95671147, 0.95658469, 0.95642734, 0.95638865, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95617169, 0.95616949, 0.95609355, 0.95609355, 0.95573395, 0.95573395, 0.95564318, 0.95486909, 0.95478505, 0.95474398, 0.95474398, 0.95457113, 0.95440865, 0.95428336, 0.95419133, 0.95410222, 0.95409507, 0.95400316, 0.95400316, 0.95387775, 0.95374382]\n"
     ]
    }
   ],
   "source": [
    "print [probs[indices[i]] for i in range(len(indices))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_edges = []\n",
    "for i in range(len(indices)):\n",
    "    predicted_edges.append(non_edges[indices[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'predicted_edges = []\\ncounter = 0\\nnode_counter = { i : 0 for i in G.nodes()}\\nfor i in range(len(indices)):\\n    if counter >452:\\n        break\\n    if node_counter[non_edges[indices[i]][0]]< 2:\\n        predicted_edges.append(non_edges[indices[i]])\\n        counter += 1\\n        node_counter[non_edges[indices[i]][0]]+=1'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"predicted_edges = []\n",
    "counter = 0\n",
    "node_counter = { i : 0 for i in G.nodes()}\n",
    "for i in range(len(indices)):\n",
    "    if counter >452:\n",
    "        break\n",
    "    if node_counter[non_edges[indices[i]][0]]< 2:\n",
    "        predicted_edges.append(non_edges[indices[i]])\n",
    "        counter += 1\n",
    "        node_counter[non_edges[indices[i]][0]]+=1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'provocateur.gr', u'olapaok.gr'), (u'alexpolisonline.com', u'frontpages.gr'), (u'alexpolisonline.com', u'google.gr'), (u'stoxasmos-politikh.blogspot.gr', u'imerodromos.gr'), (u'provocateur.gr', u'frontpages.gr')]\n"
     ]
    }
   ],
   "source": [
    "print predicted_edges[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('predicted_edges_xgb.txt', 'w') as fp:\n",
    "    for site_1, site_2 in predicted_edges:\n",
    "        fp.write(site_1+'\\t'+site_2+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
